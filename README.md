![Alt text](https://github.com/JordanMicahBennett/Supersymmetric-artificial-neural-network/blob/master/_image.png "default page")

What is the motivation behind the "Supersymmetric Artificial Neural Network?"
============================================


The "[Supersymmetric Artificial Neural Network](https://www.researchgate.net/publication/316586028_Thought_Curvature_An_underivative_hypothesis_-_on_the_%27Supersymmetric_Artificial_Neural_Network%27)" (or "**Edward Witten/String theory powered artificial neural network**") is a [Lie Superalgebra](https://en.wikipedia.org/wiki/Lie_superalgebra) aligned algorithmic learning model **(created by [myself](https://www.facebook.com/ProgrammingGodJordan) on May 10, 2016)**, based on [evidence ](https://arxiv.org/abs/0705.1134)pertaining to [Supersymmetry](https://en.wikipedia.org/wiki/Supersymmetry) in the biological brain.


To describe the **significance** of the "[Supersymmetric Artificial Neural Network](https://www.researchgate.net/publication/316586028_Thought_Curvature_An_underivative_hypothesis_-_on_the_%27Supersymmetric_Artificial_Neural_Network%27)", I will describe an **informal proof** of the **representation power** gained by **deeper abstractions** generatable by learning [supersymmetric](https://en.wikipedia.org/wiki/Supersymmetry) weights.

&nbsp;


![](https://i.imgur.com/0MF1WKV.jpg)


**Remember** that [Deep Learning](https://en.wikipedia.org/wiki/Deep_learning) is all about representation power, i.e. how much data the **artificial neural model** can **capture** from inputs, so as to produce **good guesses/hypotheses** about what the input data is talking about.

Machine learning is all about the application of families of functions that **guarantee more and more variations** in weight space.

&nbsp;

This means that machine learning researchers study what functions are best to transform the weights of the artificial neural network, such that the **weights learn** to represent **good values** for which **correct hypotheses or guesses** can be produced by the artificial neural network.

&nbsp;

**The** [**“Supersymmetric Artificial Neural Network”**](https://www.researchgate.net/publication/316586028_Thought_Curvature_An_underivative_hypothesis) is yet another way to **represent richer values** in the weights of the model; because **supersymmetric values** can allow for **more information to be captured about the input space.** For example, supersymmetric systems can capture **potential-partner** signals, which are **beyond** the feature space of **magnitude** and **phase signals** learnt in **typical** **real valued neural nets** and **deep complex neural networks** respectively. As such, a brief historical progression of geometric solution spaces for varying neural network architectures follows:

![](https://i.imgur.com/NRA0CH3.png)
paper: https://www.researchgate.net/publication/316586028_Thought_Curvature_An_underivative_hypothesis

PAPER
==================
[https://www.researchgate.net/publication/Thought_Curvature](https://www.researchgate.net/publication/316586028_Thought_Curvature_An_underivative_hypothesis_-_on_the_%27Supersymmetric_Artificial_Neural_Network%27)


SUMMARY
==================

![](https://i.imgur.com/eI6nwIy.png)

YOUTUBE-SUMMARY
==================
https://www.youtube.com/watch?v=62YVT2LlXAI


THE SUPERSYMMETRIC ARTIFICIAIL NEURAL NETWORK STEMS FROM:
==================
https://jordanmicahbennett.github.io/Supermathematics-and-Artificial-General-Intelligence/


AUTHOR PORTFOLIO
============================================
http://folioverse.appspot.com/
