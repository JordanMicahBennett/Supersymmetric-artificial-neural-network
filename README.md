![Alt text](https://github.com/JordanMicahBennett/Supersymmetric-artificial-neural-network/blob/master/_image_v2.png "default page")

Alternate-title [0]: “Thought Curvature”
============================================
“Thought Curvature” is similar to “[Thought vectors](https://en.wikipedia.org/wiki/Thought_vector)”, with the distinction that [supermanifold](https://en.wikipedia.org/wiki/Supermanifold)/[curvatures](https://en.wikipedia.org/wiki/Curvature) are used to describe the "Supersymmetric Artificial Neural Network"(SANN) model. (See [manifold](https://en.wikipedia.org/wiki/Manifold)/[curvature](https://en.wikipedia.org/wiki/Curvature) work in [geometric deep learning by Michael Bronstein et al.](https://arxiv.org/abs/1611.08097))

["Thought Curvature" or the "Supersymmetric Artificial Neural Network (2016)"](https://openreview.net/pdf?id=SJewsu6qOV) is reasonably observable as **a new branch or field of [Deep Learning](https://en.wikipedia.org/wiki/Deep_learning)** in Artificial Intelligence, called Supersymmetric Deep Learning, by Bennett. Supersymmetric Artificial Intelligence (though not Deep Gradient Descent-like machine learning) can be traced back to work by Czachor et al, concerning a "Supersymmetric Latent Semantic Analysis (2004)" based thought experiment. (See item 8 from [my repository's source](https://github.com/JordanMicahBennett/Supermathematics-and-Artificial-General-Intelligence/blob/master/1.%20Extra%20list%20of%20helpful%20resources.md#the-following-is-a-list-of-helpful-resources-that-are-useful-in-order-to-continue-the-model-inthought-curvature-paper)). Biological science/Neuroscience saw application of supersymmetry, [as far back as 2007 by Perez et al](https://arxiv.org/abs/0705.1134).


Alternate-title [1]: “Supersymmetric Gradient Descent”
============================================
In propagating small changes wrt some target space within a problem space, throughout the supersymmetric model, supersymmetric stochastic gradient descent is roughly performed. This is not to be confused for [Symmetric tensors](https://en.wikipedia.org/wiki/Symmetric_tensor) as seen in [old Higher Order Symmetric Tensor papers, that dont concern superspace, but falsely label said symmetric tensors as "supersymmetric tensors"](https://arxiv.org/pdf/1201.3424). Pertinently, [see this paper, describing the phenomena of "super" tensor labelling errors](https://arxiv.org/pdf/0802.1681). Notably, [even recent higher order tensor papers, that likewise dont concern superspace](https://arxiv.org/pdf/1410.4536.pdf) are still invalidly commiting the "super" labelling error, as described in the [error indicating paper prior cited](https://arxiv.org/pdf/0802.1681)).

Supersymmetric Artificial Neural Network in Layman's terms
============================================
[Article/My “Supersymmetric Artificial Neural Network” in layman’s terms](https://medium.com/@jordanmicahbennett/article-ai-the-supersymmetric-artificial-neural-network-in-laymans-terms-4f416d7d76da)

Wikiversity Page (Wikipedia-like format)
============================================
https://en.wikiversity.org/wiki/Supersymmetric_Artificial_Neural_Network

![Alt text](https://github.com/JordanMicahBennett/Supersymmetric-artificial-neural-network/blob/master/_wikiversity_image.png "default page")


Work by a Physics person, who communicated to me via email that he became attracted to my idea in February 2019
============================================
See the paper of a physics person, [Mitchell Porter](https://physics.stackexchange.com/users/1486/mitchell-porter) who became attracted to my idea in **February 2019**, and wrote a paper in **March 2019** citing my work: https://www.researchgate.net/publication/332103958_2019_Applications_of_super-mathematics_to_machine_learning


What is the motivation behind the "Supersymmetric Artificial Neural Network?"
============================================

The "[Supersymmetric Artificial Neural Network](https://www.researchgate.net/publication/316586028_Thought_Curvature_An_underivative_hypothesis_-_on_the_%27Supersymmetric_Artificial_Neural_Network%27)" (or "**Edward Witten/String theory powered artificial neural network**") is a [Lie Superalgebra](https://en.wikipedia.org/wiki/Lie_superalgebra) aligned algorithmic learning model **(started/created by [myself](https://www.facebook.com/ProgrammingGodJordan) on May 10, 2016)**, based on [evidence ](https://arxiv.org/abs/0705.1134)pertaining to [Supersymmetry](https://en.wikipedia.org/wiki/Supersymmetry) in the biological brain.


To describe the **significance** of the "[Supersymmetric Artificial Neural Network](https://www.researchgate.net/publication/316586028_Thought_Curvature_An_underivative_hypothesis_-_on_the_%27Supersymmetric_Artificial_Neural_Network%27)", I will describe an **informal proof** of the **representation power** gained by **deeper abstractions** generatable by learning [supersymmetric](https://en.wikipedia.org/wiki/Supersymmetry) weights.

&nbsp;


![](https://i.imgur.com/0MF1WKV.jpg)


**Remember** that [Deep Learning](https://en.wikipedia.org/wiki/Deep_learning) is all about representation power, i.e. how much data the **artificial neural model** can **capture** from inputs, so as to produce **good guesses/hypotheses** about what the input data is talking about.

Machine learning is all about the application of families of functions that **guarantee more and more variations** in weight space.

&nbsp;

This means that machine learning researchers study what functions are best to transform the weights of the artificial neural network, such that the **weights learn** to represent **good values** for which **correct hypotheses or guesses** can be produced by the artificial neural network.

&nbsp;

**The** [**“Supersymmetric Artificial Neural Network”**](https://www.researchgate.net/publication/316586028_Thought_Curvature_An_underivative_hypothesis) is yet another way to **represent richer values** in the weights of the model; because **supersymmetric values** can allow for **more information to be captured about the input space.** For example, supersymmetric systems can capture **potential-partner** signals, which are **beyond** the feature space of **magnitude** and **phase signals** learnt in **typical** **real valued neural nets** and **deep complex neural networks** respectively. As such, a brief historical progression of geometric solution spaces for varying neural network architectures follows:

![](https://i.imgur.com/NRA0CH3.png)
paper: https://www.researchgate.net/publication/316586028_Thought_Curvature_An_underivative_hypothesis

PAPER
==================
[Open Review/Thought Curvature](https://openreview.net/pdf?id=SJewsu6qOV)

Artificial neural network/symmetry group landscape visualization
===================
![](https://i.imgur.com/KdcuSUa.png)
paper: https://www.researchgate.net/publication/316586028_Thought_Curvature_An_underivative_hypothesis

ORIGINAL PAGE
===================
https://jordanmicahbennett.github.io/Supermathematics-and-Artificial-General-Intelligence/

GLOBAL CONFERENCE(S)/JOURNAL(S)
==================

1. The "Supersymmetric Artificial Neural Network Model" [was accepted to a String Theory conference called "String Theory and Cosmology Gordon research conference"](https://drive.google.com/file/d/1gtIxjZ2rJ9RbhqdnoyP_8YlFEEWg0FUO/view), where the likes of far smarter persons than myself, like PhD physicists such as "Hitoshi Murayama" will be speaking.

Website:
https://www.grc.org/string-theory-and-cosmology-conference/2019/ 

**Note**: For those who don't know, String Theory is referred to as Science's best theory of explaining the origin of the universe, championed by some of the world's smartest people, including Edward Witten, referred to as the "World's smartest physicist", on par with Newton and Einstein.

Youtube video showcasing email/acceptance letters: https://www.youtube.com/watch?v=BuE7dtYaKA8

![Alt text](https://github.com/JordanMicahBennett/Supersymmetric-artificial-neural-network/blob/master/_image_icmlsc.png "default page")

2. The "[Supersymmetric Artificial Neural Network](https://github.com/JordanMicahBennett/Supersymmetric-artificial-neural-network/)" was accepted to "[The 3rd International Conference on Machine Learning and Soft Computing](http://www.icmlsc.org/)".

![Alt text](https://github.com/JordanMicahBennett/Supersymmetric-artificial-neural-network/blob/master/_image_gcainn.jpg "default page")

3. The "[Supersymmetric Artificial Neural Network](https://github.com/JordanMicahBennett/Supersymmetric-artificial-neural-network/)" was accepted to "[The 6th global conference for artificial intelligence and neural networks](https://neuralnetworks.conferenceseries.com/)".


SUMMARY
==================

![](https://i.imgur.com/k99apx8.png)

YOUTUBE-SUMMARY
==================
https://www.youtube.com/watch?v=62YVT2LlXAI


LET'S GET EVEN DEEPER!
==================
[Researchgate/Why is the purpose of human life to create Artificial General Intelligence?](https://www.researchgate.net/publication/319235750_Why_is_the_purpose_of_human_life_to_create_Artificial_General_Intelligence)


AUTHOR PORTFOLIO
============================================
http://folioverse.appspot.com/
